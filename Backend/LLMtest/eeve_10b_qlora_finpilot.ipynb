{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEVE-10.8B QLoRA Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.24.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2023.4.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is still looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading huggingface_hub-0.26.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.4-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fsspec[http]<=2024.12.0,>=2023.1.0 (from datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.3.1-py3-none-any.whl (484 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.1/464.1 kB\u001b[0m \u001b[31m179.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m237.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m186.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m132.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 kB\u001b[0m \u001b[31m204.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m171.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m162.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, xxhash, tzdata, tqdm, requests, pyarrow, propcache, multidict, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.3.1 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.12.0 huggingface-hub-0.28.1 multidict-6.1.0 multiprocess-0.70.16 pandas-2.2.3 propcache-0.2.1 pyarrow-19.0.1 pytz-2025.1 requests-2.32.3 tqdm-4.67.1 tzdata-2025.1 xxhash-3.5.0 yarl-1.18.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.1.0+cu118)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.24.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m132.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.28.1)\n",
      "Collecting safetensors>=0.4.3 (from accelerate)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.1/342.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, accelerate\n",
      "Successfully installed accelerate-1.4.0 safetensors-0.5.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting peft\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu118)\n",
      "Collecting transformers (from peft)\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.4.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.28.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
      "Collecting regex!=2019.12.17 (from transformers->peft)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.22,>=0.21 (from transformers->peft)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m201.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m192.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tokenizers, transformers, peft\n",
      "Successfully installed peft-0.14.0 regex-2024.11.6 tokenizers-0.21.0 transformers-4.49.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting trl\n",
      "  Downloading trl-0.15.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.10/dist-packages (from trl) (1.4.0)\n",
      "Requirement already satisfied: datasets>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from trl) (3.3.1)\n",
      "Collecting rich (from trl)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.49.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (2.1.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (0.28.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (0.5.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.21.0->trl) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.11.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0->trl) (0.21.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->trl)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.16.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (4.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.18.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->trl)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2022.12.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Downloading trl-0.15.1-py3-none-any.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: mdurl, markdown-it-py, rich, trl\n",
      "Successfully installed markdown-it-py-3.0.0 mdurl-0.1.2 rich-13.9.4 trl-0.15.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (4.4.0)\n",
      "Collecting typing_extensions\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing_extensions\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "Successfully installed typing_extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch)\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m181.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m160.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m238.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m132.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m135.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m196.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.6.0 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 triton-3.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.24.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting korouge_score\n",
      "  Downloading korouge_score-0.1.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting absl-py (from korouge_score)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting nltk (from korouge_score)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from korouge_score) (1.24.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from korouge_score) (1.16.0)\n",
      "Collecting click (from nltk->korouge_score)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk->korouge_score)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->korouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->korouge_score) (4.67.1)\n",
      "Downloading korouge_score-0.1.4-py3-none-any.whl (28 kB)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m162.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m153.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: joblib, click, absl-py, nltk, korouge_score\n",
      "Successfully installed absl-py-2.1.0 click-8.1.8 joblib-1.4.2 korouge_score-0.1.4 nltk-3.9.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting konlpy\n",
      "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting JPype1>=0.7.0 (from konlpy)\n",
      "  Downloading jpype1-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
      "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.24.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
      "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jpype1-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m191.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
      "Successfully installed JPype1-1.5.2 konlpy-0.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets\n",
    "!pip install -U bitsandbytes\n",
    "!pip install -U accelerate\n",
    "!pip install -U peft\n",
    "!pip install -U trl\n",
    "!pip install -U typing_extensions\n",
    "!pip install -U torch\n",
    "!pip install -U datasets\n",
    "!pip install -U korouge_score\n",
    "!pip install -U konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.17.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.13.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.9)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.8)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (3.11.0)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 (from wandb)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.6)\n",
      "Collecting pydantic<3,>=2.6 (from wandb)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.22.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.6->wandb)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=2.6->wandb)\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m167.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m156.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m159.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m183.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.22.0-py2.py3-none-any.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.8/325.8 kB\u001b[0m \u001b[31m169.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, pydantic-core, protobuf, docker-pycreds, annotated-types, pydantic, gitdb, gitpython, wandb\n",
      "Successfully installed annotated-types-0.7.0 docker-pycreds-0.4.0 gitdb-4.0.12 gitpython-3.1.44 protobuf-5.29.3 pydantic-2.10.6 pydantic-core-2.27.2 sentry-sdk-2.22.0 setproctitle-1.3.4 smmap-5.0.2 wandb-0.19.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    BitsAndBytesConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    EarlyStoppingCallback,\n",
    "    Trainer,\n",
    "    TextStreamer,\n",
    "    pipeline,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    TaskType,\n",
    "    PeftModel,\n",
    "    PeftConfig,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from korouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"FinPilot\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbb41668dd645a9af0887b449368cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src='https://wandb.ai/FinPilot/login/workspace?jupyter=true' style='border:none;width:100%;height:420px;'></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x7ab5a1fe69e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"MartinusChoi/FinPilot\", split=\"train\")\n",
    "test_dataset = load_dataset(\"MartinusChoi/FinPilot\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set PLM Into QLoRA Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb79ec90c47e419fb8191efce71e0cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"yanolja/EEVE-Korean-Instruct-10.8B-v1.0\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                     # Load model in 4bit precision\n",
    "    bnb_4bit_quant_type='nf4',             # Pre-trained model has to be quantization in 4bit nf type\n",
    "    bnb_4bit_use_double_quant=True,        # Use double-qauntization of QLoRA\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # Pre-trained model has to be loaded in BF16 dtype\n",
    ")\n",
    "\n",
    "plm = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    token=True,\n",
    "    quantization_config=bnb_config,        # Use bitsandbytes config\n",
    "    device_map='auto',                     # auto : HF Accelerate determines which GPU to allocate for each layer of the model.\n",
    "    trust_remote_code=True                 # Setting for use EEVE model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('yanolja/EEVE-Korean-Instruct-10.8B-v1.0', token=True,)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 69,206,016 || all params: 10,874,130,432 || trainable%: 0.6364\n"
     ]
    }
   ],
   "source": [
    "flm = prepare_model_for_kbit_training(plm)\n",
    "\n",
    "lora_alpha = 32\n",
    "lora_dropout = 0.05\n",
    "lora_rank = 32\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_rank,\n",
    "    bias='none',\n",
    "    task_type='CAUSAL_LM',\n",
    "    target_modules=['q_proj','k_proj','v_proj','o_proj','gate_proj']\n",
    ")\n",
    "\n",
    "flm=get_peft_model(flm, peft_config)\n",
    "flm.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class SaveOnLowerEvalLossCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.best_eval_loss = float(\"inf\")\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        current_loss = metrics.get(\"eval_loss\")\n",
    "        # eval_loss가 존재하고, 이전보다 낮은 경우에만 저장하도록 설정\n",
    "        if current_loss is not None and current_loss < self.best_eval_loss:\n",
    "            self.best_eval_loss = current_loss\n",
    "            control.should_save = True   # 새로운 최저 loss일 경우 저장 실행\n",
    "        else:\n",
    "            control.should_save = False  # 개선되지 않으면 저장하지 않음\n",
    "        return control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_arguments = transformers.TrainingArguments(\n",
    "    output_dir = './train_output',\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 2,                                               # 배치 크기가 줄어들면 기울기 누적 단계가 2배 증가\n",
    "    optim = 'paged_adamw_32bit',                                                   # 더 나은 메모리 관리를 위해 페이징을 활성화\n",
    "    save_strategy='steps',                                                         # 학습 중에 채택할 체크포인트 save strategy\n",
    "    save_steps = 10,                                                               # 두 개의 체크포인트가 저장되기 전의 업데이트 단계 수\n",
    "    logging_steps = 5,                                                            # 두 로그 사이의 업데이트 단계 수\n",
    "    learning_rate = 2e-4,                                                          # AdamW 최적화 프로그램의 학습률\n",
    "    max_grad_norm = 0.3,                                                           # 최대 그라데이션 표준(gradient clipping)\n",
    "    max_steps = 500,                                                                # 60 단계 동안 학습\n",
    "    warmup_ratio = 0.03,                                                           # 0 에서 learning_rate 까지 선형 준비에 사용되는 단계 수\n",
    "    lr_scheduler_type = 'cosine',                                                  # 학습률 스케줄러\n",
    "    report_to = 'wandb',                                                           # You can find your API key in your browser here: https://wandb.ai/authorize\n",
    "    evaluation_strategy='steps',  # perform evaluation periodically\n",
    "    eval_steps=10,                # evaluate every 10 steps\n",
    "    load_best_model_at_end=True,  # load the best model based on eval_loss\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    # Dict for store 'rouge' score per predicted summary\n",
    "    scores = {\n",
    "        \"rouge1\": [],\n",
    "        \"rouge2\": [],\n",
    "        \"rougeL\": [],\n",
    "        \"rougeLsum\": []\n",
    "    }\n",
    "\n",
    "    # 한국어 rouge score 계산 인스턴스 생성\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'])\n",
    "\n",
    "    # 모델의 예측 정보 파싱\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # 모델 예측의 각 토큰의 대한 logit을 토큰으로 변환\n",
    "    # prediction shape : (batch, max_length, 51200)\n",
    "    # 마지막 차원(51200)은 어휘 사전 크기 만큼의 logit\n",
    "    # np.argmax() 를 활용해 가장 확률 높은 token id로 변환\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    # labels에 포함된 -100 값을 pad_token_id로 대체하여 디코딩 에러(OverflowError)를 방지\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    for pred, ref in zip(decoded_preds, decoded_labels):\n",
    "        score = scorer.score(ref, pred)\n",
    "        for rouge_type in scores.keys():\n",
    "            scores[rouge_type].append(score[rouge_type].fmeasure)\n",
    "    \n",
    "    avg_scores = {rouge_type: sum(score_list) / len(score_list) * 100 \n",
    "                  for rouge_type, score_list in scores.items()}\n",
    "    return avg_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6222/645764768.py:1: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6194e91cd2f64a32af59c118b2550258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/406 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338f0cb20edb49f1899f1016756271fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/406 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa0cb39abb8498398b424b1d56e5b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab268a015ba4b4abd042d0c8f117f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=flm,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[SaveOnLowerEvalLossCallback(), EarlyStoppingCallback(early_stopping_patience=10)]\n",
    ")\n",
    "\n",
    "\n",
    "for name, module in trainer.model.named_modules():\n",
    "    if 'norm' in name:\n",
    "        module = module.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmartinus-choi\u001b[0m (\u001b[33mFinPilot\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250219_004850-s8xh1gsz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/FinPilot/FinPilot/runs/s8xh1gsz' target=\"_blank\">./train_output</a></strong> to <a href='https://wandb.ai/FinPilot/FinPilot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/FinPilot/FinPilot' target=\"_blank\">https://wandb.ai/FinPilot/FinPilot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/FinPilot/FinPilot/runs/s8xh1gsz' target=\"_blank\">https://wandb.ai/FinPilot/FinPilot/runs/s8xh1gsz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/500 18:22 < 36:06, 0.15 it/s, Epoch 1/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.199900</td>\n",
       "      <td>1.191314</td>\n",
       "      <td>45.303187</td>\n",
       "      <td>23.955184</td>\n",
       "      <td>40.997370</td>\n",
       "      <td>44.096028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.078500</td>\n",
       "      <td>1.079117</td>\n",
       "      <td>49.647431</td>\n",
       "      <td>27.214074</td>\n",
       "      <td>45.483246</td>\n",
       "      <td>48.483383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.009400</td>\n",
       "      <td>1.069564</td>\n",
       "      <td>49.854152</td>\n",
       "      <td>27.887221</td>\n",
       "      <td>45.896612</td>\n",
       "      <td>48.814689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.056100</td>\n",
       "      <td>1.065504</td>\n",
       "      <td>50.118459</td>\n",
       "      <td>28.303355</td>\n",
       "      <td>46.020409</td>\n",
       "      <td>48.881543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.031900</td>\n",
       "      <td>1.054673</td>\n",
       "      <td>50.395338</td>\n",
       "      <td>28.891147</td>\n",
       "      <td>46.334466</td>\n",
       "      <td>49.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.924600</td>\n",
       "      <td>1.065562</td>\n",
       "      <td>49.702126</td>\n",
       "      <td>27.949690</td>\n",
       "      <td>46.333554</td>\n",
       "      <td>48.860893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.899400</td>\n",
       "      <td>1.050036</td>\n",
       "      <td>50.254053</td>\n",
       "      <td>28.754552</td>\n",
       "      <td>46.474233</td>\n",
       "      <td>49.162414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.784500</td>\n",
       "      <td>1.072389</td>\n",
       "      <td>50.524289</td>\n",
       "      <td>28.655703</td>\n",
       "      <td>46.568255</td>\n",
       "      <td>49.544158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.882800</td>\n",
       "      <td>1.075470</td>\n",
       "      <td>50.019461</td>\n",
       "      <td>28.444443</td>\n",
       "      <td>46.475781</td>\n",
       "      <td>48.958156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.842200</td>\n",
       "      <td>1.090359</td>\n",
       "      <td>49.825245</td>\n",
       "      <td>28.213815</td>\n",
       "      <td>46.313327</td>\n",
       "      <td>48.883944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.479400</td>\n",
       "      <td>1.229370</td>\n",
       "      <td>48.969980</td>\n",
       "      <td>26.941293</td>\n",
       "      <td>45.421185</td>\n",
       "      <td>47.957481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.479000</td>\n",
       "      <td>1.148895</td>\n",
       "      <td>50.042535</td>\n",
       "      <td>28.043404</td>\n",
       "      <td>46.414859</td>\n",
       "      <td>48.948590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.442700</td>\n",
       "      <td>1.195819</td>\n",
       "      <td>48.993063</td>\n",
       "      <td>27.640328</td>\n",
       "      <td>45.703432</td>\n",
       "      <td>48.015807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.432700</td>\n",
       "      <td>1.192288</td>\n",
       "      <td>48.977313</td>\n",
       "      <td>27.511298</td>\n",
       "      <td>45.882451</td>\n",
       "      <td>47.963833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.461700</td>\n",
       "      <td>1.181773</td>\n",
       "      <td>49.400596</td>\n",
       "      <td>28.023535</td>\n",
       "      <td>46.202065</td>\n",
       "      <td>48.558924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.383400</td>\n",
       "      <td>1.183975</td>\n",
       "      <td>49.407980</td>\n",
       "      <td>27.301876</td>\n",
       "      <td>46.092275</td>\n",
       "      <td>48.416866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>1.213394</td>\n",
       "      <td>48.996718</td>\n",
       "      <td>27.362033</td>\n",
       "      <td>45.883998</td>\n",
       "      <td>47.860406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./train_output/checkpoint-10)... Done. 1.0s\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./train_output/checkpoint-20)... Done. 1.0s\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./train_output/checkpoint-30)... Done. 1.0s\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./train_output/checkpoint-40)... Done. 1.0s\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./train_output/checkpoint-50)... Done. 1.0s\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./train_output/checkpoint-70)... Done. 1.0s\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=170, training_loss=0.7680965206202339, metrics={'train_runtime': 1107.9006, 'train_samples_per_second': 1.805, 'train_steps_per_second': 0.451, 'total_flos': 2.662953950104781e+16, 'train_loss': 0.7680965206202339})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flm.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare between PLM and FLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      "##Instruction : 삼성전자는 메모리 반도체 분야에서 세계적인 리더로 자리잡고 있습니다. 최근 HBM(고대역폭 메모리) 기술 경쟁력을 회복하며 시장에서의 입지를 강화하고 있습니다. 이는 AI 및 데이터 센터 수요 증가에 따른 것으로, 삼성전자는 이러한 수요에 대응하기 위해 기술 개발에 박차를 가하고 있습니다. 이 텍스트를 요약해줘\n",
      "\n",
      "##Response : \n",
      "삼성전자는 메모리 반도체 분야에서 세계적인 리더로 자리 잡고 있으며, 최근 HBM 기술 경쟁력을 회복하며 시장 입지를 강화하고 있습니다. 이는 AI 및 데이터 센터 수요 증가에 따른 것으로, 삼성전자는 이러한 수요에 대응하기 위해 기술 개발에 집중하고 있습니다.<eos>\n"
     ]
    }
   ],
   "source": [
    "# 예제 입력 텍스트\n",
    "input_text = \"\"\"\n",
    "##Instruction : 삼성전자는 메모리 반도체 분야에서 세계적인 리더로 자리잡고 있습니다. 최근 HBM(고대역폭 메모리) 기술 경쟁력을 회복하며 시장에서의 입지를 강화하고 있습니다. 이는 AI 및 데이터 센터 수요 증가에 따른 것으로, 삼성전자는 이러한 수요에 대응하기 위해 기술 개발에 박차를 가하고 있습니다. 이 텍스트를 요약해줘\n",
    "\n",
    "##Response : \n",
    "\"\"\"\n",
    "\n",
    "# FLM 모델 사용\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# 입력 텐서를 GPU로 이동\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "# 모델 실행\n",
    "output = flm.generate(**inputs, max_length=200)\n",
    "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Output:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 삼성전자는 메모리 반도체 분야에서 세계적인 리더로 자리잡고 있습니다. 최근 HBM(고대역폭 메모리) 기술 경쟁력을 회복하며 시장에서의 입지를 강화하고 있습니다. 이는 AI 및 데이터 센터 수요 증가에 따른 것으로, 삼성전자는 이러한 수요에 대응하기 위해 기술 개발에 박차를 가하고 있습니다. 이 텍스트를 요약해줘.\n",
      "\n",
      "삼성전자는 메모리 반도체 분야에서 세계적인 리더로 자리 잡고 있으며, 특히 HBM(고대역폭 메모리) 기술 경쟁력을 회복하며 시장에서의 입지를 강화하고 있습니다. 이는 AI 및 데이터 센터 수요 증가에 따른 것으로, 삼성전자는 이러한 수요에 대응하기 위해 기술 개발에 집중하고 있습니다.<eos>\n"
     ]
    }
   ],
   "source": [
    "# 예제 입력 텍스트\n",
    "input_text = \"삼성전자는 메모리 반도체 분야에서 세계적인 리더로 자리잡고 있습니다. 최근 HBM(고대역폭 메모리) 기술 경쟁력을 회복하며 시장에서의 입지를 강화하고 있습니다. 이는 AI 및 데이터 센터 수요 증가에 따른 것으로, 삼성전자는 이러한 수요에 대응하기 위해 기술 개발에 박차를 가하고 있습니다. 이 텍스트를 요약해줘\"\n",
    "\n",
    "# plm 모델 사용\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "# 입력 텐서를 GPU로 이동\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "output = plm.generate(**inputs, max_length=1024)\n",
    "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Output:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      "##Instruction : 삼성전자는 메모리 반도체 분야에서 세계적인 리더로 자리잡고 있습니다. 최근 HBM(고대역폭 메모리) 기술 경쟁력을 회복하며 시장에서의 입지를 강화하고 있습니다. 이는 AI 및 데이터 센터 수요 증가에 따른 것으로, 삼성전자는 이러한 수요에 대응하기 위해 기술 개발에 박차를 가하고 있습니다. 이 텍스트를 확장해줘\n",
      "\n",
      "##Response : \n",
      "\n",
      "삼성전자는 메모리 반도체 분야에서 세계적인 리더로 자리 잡고 있으며, 이는 회사의 기술력과 시장에서의 입지를 증명하는 중요한 지표입니다. 특히, 최근 삼성전자는 HBM(고대역폭 메모리) 기술 경쟁력을 회복하며 시장에서의 입지를 더욱 강화하고 있습니다. 이 기술은 인공지능(AI) 및 데이터 센터 수요 증가에 따른 것으로, 삼성전자는 이러한 수요에 대응하기 위해 기술 개발에 박차를 가하고 있습니다.\n",
      "\n",
      "HBM 기술은 고성능 컴퓨팅 시스템에 필수적인 요소로, 대량의 데이터를 빠르게 처리할 수 있는 능력을 제공합니다. 이는 특히 AI와 데이터 센터 분야에서 중요한 역할을 하며, 이러한 시스템은 대량의 데이터를 실시간으로 처리해야 하기 때문입니다. 삼성전자는 HBM 기술을 통해 이러한 시스템의 성능을 향상시키고, 고객들에게 보다 혁신적이고 효율적인 솔루션을 제공하기 위해 노력하고 있습니다.\n",
      "\n",
      "삼성전자는 HBM 기술 개발에 있어 선도적인 역할을 하고 있으며, 이는 회사의 기술 리더십을 보여주는 중요한 지표입니다. 회사는 지속적인 연구개발을 통해 HBM 기술의 한계를 넘어서는 혁신적인 솔루션을 제공하고 있으며, 이를 통해 시장에서의 입지를 더욱 강화하고 있습니다. 이러한 노력은 삼성전자가 메모리 반도체 분야에서 세계적인 리더로 자리 잡는 데 큰 기여를 하고 있습니다.\n",
      "\n",
      "삼성전자는 앞으로도 HBM 기술을 비롯한 다양한 메모리 솔루션을 통해 시장에서의 입지를 더욱 강화할 계획입니다. 이를 통해 회사는 고객들에게 보다 혁신적이고 효율적인 솔루션을 제공하며, 메모리 반도체 시장에서 지속적인 성장을 이루고자 합니다. 이러한 노력은 삼성전자가 메모리 반도체 분야에서 세계적인 리더로서의 위치를 더욱 공고히 하는 데 기여할 것입니다.<eos>\n"
     ]
    }
   ],
   "source": [
    "# 예제 입력 텍스트\n",
    "input_text = \"\"\"\n",
    "##Instruction : 삼성전자는 메모리 반도체 분야에서 세계적인 리더로 자리잡고 있습니다. 최근 HBM(고대역폭 메모리) 기술 경쟁력을 회복하며 시장에서의 입지를 강화하고 있습니다. 이는 AI 및 데이터 센터 수요 증가에 따른 것으로, 삼성전자는 이러한 수요에 대응하기 위해 기술 개발에 박차를 가하고 있습니다. 이 텍스트를 확장해줘\n",
    "\n",
    "##Response : \n",
    "\"\"\"\n",
    "\n",
    "# FLM 모델 사용\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# 입력 텐서를 GPU로 이동\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "# 모델 실행\n",
    "output = flm.generate(**inputs, max_length=1024)\n",
    "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Output:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 삼성전자는 메모리 반도체 분야에서 세계적인 리더로 자리잡고 있습니다. 최근 HBM(고대역폭 메모리) 기술 경쟁력을 회복하며 시장에서의 입지를 강화하고 있습니다. 이는 AI 및 데이터 센터 수요 증가에 따른 것으로, 삼성전자는 이러한 수요에 대응하기 위해 기술 개발에 박차를 가하고 있습니다. 이 텍스트를 확장해줘.\n",
      "\n",
      "삼성전자는 메모리 반도체 분야에서 세계적인 리더로 자리 잡고 있으며, 이는 회사의 핵심 사업 중 하나입니다. 이 회사는 다양한 유형의 메모리 반도체를 생산하고 있으며, 그중에서도 특히 DDR(Double Data Rate) SDRAM, GDDR(Graphics Double Data Rate) SDRAM, LPDDR(Low Power Double Data Rate) SDRAM, 그리고 HBM(High Bandwidth Memory) 등이 주요 제품군에 속합니다. 이러한 제품들은 다양한 전자 제품, 특히 컴퓨터, 스마트폰, 게임 콘솔, 데이터 센터 등에서 필수적인 역할을 합니다.\n",
      "\n",
      "최근 삼성전자는 HBM 기술 경쟁력을 회복하며 시장에서 입지를 강화하고 있습니다. HBM은 고성능 컴퓨팅 및 그래픽 처리 시스템에 사용되는 고대역폭 메모리 기술로, 대량의 데이터를 빠르게 처리할 수 있는 능력이 요구되는 분야에서의 수요가 증가하고 있습니다. 특히, 인공지능(AI)과 데이터 센터의 수요가 급증하면서 HBM의 중요성이 더욱 부각되고 있습니다.\n",
      "\n",
      "삼성전자는 이러한 수요에 대응하기 위해 기술 개발에 박차를 가하고 있습니다. 회사는 HBM의 성능을 향상시키기 위해 다양한 기술을 접목하고 있으며, 특히 3D 스택형 구조와 초고속 데이터 전송 기술을 통해 HBM의 한계를 넘어서는 제품을 개발하고 있습니다. 이러한 노력은 삼성전자가 메모리 반도체 시장에서 선도적인 위치를 유지하는 데 중요한 역할을 하고 있습니다.\n",
      "\n",
      "삼성전자는 또한 HBM의 응용 분야를 확장하기 위해 노력하고 있습니다. 예를 들어, HBM을 데이터 센터의 메모리 솔루션으로 활용하거나, 고성능 그래픽 처리 시스템에 적용하는 등 다양한 분야로 HBM의 적용 가능성을 넓히고 있습니다. 이러한 노력은 삼성전자가 메모리 반도체 시장에서 지속적인 성장을 이루고, 기술 리더십을 유지하는 데 기여할 것입니다.<eos>\n"
     ]
    }
   ],
   "source": [
    "# 예제 입력 텍스트\n",
    "input_text = \"삼성전자는 메모리 반도체 분야에서 세계적인 리더로 자리잡고 있습니다. 최근 HBM(고대역폭 메모리) 기술 경쟁력을 회복하며 시장에서의 입지를 강화하고 있습니다. 이는 AI 및 데이터 센터 수요 증가에 따른 것으로, 삼성전자는 이러한 수요에 대응하기 위해 기술 개발에 박차를 가하고 있습니다. 이 텍스트를 확장해줘\"\n",
    "\n",
    "# plm 모델 사용\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "# 입력 텐서를 GPU로 이동\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "output = plm.generate(**inputs, max_length=1024)\n",
    "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Output:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      "##Instruction : 파인텍은 2008년 설립해 끊임없는 R&D 투자와 우수 인력 확보로 전문적인 디스플레이 소재 분야의 선도 기업으로 성장해 왔다. 파인텍은 창립 이래 지속적인 연구 개발로 디스플레이 BLU를 국산화했고, 세계 최초로 폴더블 디스플레이 제조장비를 개발하는 등 디스플레이 산업에서 첨단 기술을 선도하는 기업으로 자리 잡았다. 파인텍은 디스플레이 토털 솔루션 기업을 뛰어넘어 이차전지 장비와 센서 사업에서의 끊임없는 도전과 혁신으로 글로벌 일류 기업으로 위상을 확고히 해 나가고 있다.일진디스플레이의 사업부는 크게 사파이어사업부와 터치사업부로 나뉜다. 사파이어사업부는 발광다이오드(LED)용 사파이어 웨이퍼를 주로 생산하고, 터치사업부는 휴대폰이나 태블릿에 쓰이는 터치스크린 패널을 제조한다. 일진디스플레이의 매출 90% 이상이 터치사업부에서 발생하고, 사파이어사업부의 매출 비중은 10%도 되지 않는다. 하지만 사파이어사업부에 대한 기대는 상당하다. 세계적으로 마이크로 LED 시장이 성장세에 있는데, 마이크로 LED 제조를 위해서는 사파이어 웨이퍼가 필요하기 때문이다. 마이크로 LED는 일반 LED에 비해 길이와 넓이가 각각 10분의 1, 100분의 1 수준이다. 다만, 아직까지는 기술력 등의 문제로 마이크로 LED를 사용하는 기기가 많지 않다. 시장조사기관 마켓앤드마켓은 마이크로 LED 시장 규모가 2020년 17억 달러(약 2조 1,250억 원)에서 2025년 199억 달러(약 25조 원)로 성장할 것으로 전망했다. 마이크로 LED는 스마트워치, 가상현실(VR) 등의 기기를 통해 시장이 형성되면서 향후에는 태블릿, 스마트폰 분야로 확대될 것으로 예상된다. 마이크로 LED 시장이 개화되면 사파이어 소재에 대한 수요가 급격히 늘어날 것으로 전망되며 사파이어 웨이퍼의 가격도 상승할 것으로 기대된다. 이 텍스트를 요약해줘.\n",
      "\n",
      "##Response : \n",
      "파인텍은 2008년 설립된 디스플레이 소재 선도 기업으로, BLU 국산화와 폴더블 디스플레이 제조장비 개발로 첨단 기술을 선도하고 있다. 최근에는 이차전지 장비와 센서 사업에서도 혁신을 추구하며 글로벌 일류 기업으로 성장하고 있다. 일진디스플레이는 사파이어와 터치스크린 패널을 생산하며, 마이크로 LED 시장의 성장으로 사파이어 웨이퍼에 대한 기대감이 크다. 마이크로 LED 시장은 2025년까지 199억 달러로 성장할 것으로 전망되며, 사파이어 소재 수요도 증가할 것으로 기대된다.<eos>\n"
     ]
    }
   ],
   "source": [
    "# 예제 입력 텍스트\n",
    "input_text = \"\"\"\n",
    "##Instruction : 파인텍은 2008년 설립해 끊임없는 R&D 투자와 우수 인력 확보로 전문적인 디스플레이 소재 분야의 선도 기업으로 성장해 왔다. 파인텍은 창립 이래 지속적인 연구 개발로 디스플레이 BLU를 국산화했고, 세계 최초로 폴더블 디스플레이 제조장비를 개발하는 등 디스플레이 산업에서 첨단 기술을 선도하는 기업으로 자리 잡았다. 파인텍은 디스플레이 토털 솔루션 기업을 뛰어넘어 이차전지 장비와 센서 사업에서의 끊임없는 도전과 혁신으로 글로벌 일류 기업으로 위상을 확고히 해 나가고 있다.일진디스플레이의 사업부는 크게 사파이어사업부와 터치사업부로 나뉜다. 사파이어사업부는 발광다이오드(LED)용 사파이어 웨이퍼를 주로 생산하고, 터치사업부는 휴대폰이나 태블릿에 쓰이는 터치스크린 패널을 제조한다. 일진디스플레이의 매출 90% 이상이 터치사업부에서 발생하고, 사파이어사업부의 매출 비중은 10%도 되지 않는다. 하지만 사파이어사업부에 대한 기대는 상당하다. 세계적으로 마이크로 LED 시장이 성장세에 있는데, 마이크로 LED 제조를 위해서는 사파이어 웨이퍼가 필요하기 때문이다. 마이크로 LED는 일반 LED에 비해 길이와 넓이가 각각 10분의 1, 100분의 1 수준이다. 다만, 아직까지는 기술력 등의 문제로 마이크로 LED를 사용하는 기기가 많지 않다. 시장조사기관 마켓앤드마켓은 마이크로 LED 시장 규모가 2020년 17억 달러(약 2조 1,250억 원)에서 2025년 199억 달러(약 25조 원)로 성장할 것으로 전망했다. 마이크로 LED는 스마트워치, 가상현실(VR) 등의 기기를 통해 시장이 형성되면서 향후에는 태블릿, 스마트폰 분야로 확대될 것으로 예상된다. 마이크로 LED 시장이 개화되면 사파이어 소재에 대한 수요가 급격히 늘어날 것으로 전망되며 사파이어 웨이퍼의 가격도 상승할 것으로 기대된다. 이 텍스트를 요약해줘.\n",
    "\n",
    "##Response : \n",
    "\"\"\"\n",
    "\n",
    "# FLM 모델 사용\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# 입력 텐서를 GPU로 이동\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "# 모델 실행\n",
    "output = flm.generate(**inputs, max_length=1024)\n",
    "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Output:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 파인텍은 2008년 설립해 끊임없는 R&D 투자와 우수 인력 확보로 전문적인 디스플레이 소재 분야의 선도 기업으로 성장해 왔다. 파인텍은 창립 이래 지속적인 연구 개발로 디스플레이 BLU를 국산화했고, 세계 최초로 폴더블 디스플레이 제조장비를 개발하는 등 디스플레이 산업에서 첨단 기술을 선도하는 기업으로 자리 잡았다. 파인텍은 디스플레이 토털 솔루션 기업을 뛰어넘어 이차전지 장비와 센서 사업에서의 끊임없는 도전과 혁신으로 글로벌 일류 기업으로 위상을 확고히 해 나가고 있다.일진디스플레이의 사업부는 크게 사파이어사업부와 터치사업부로 나뉜다. 사파이어사업부는 발광다이오드(LED)용 사파이어 웨이퍼를 주로 생산하고, 터치사업부는 휴대폰이나 태블릿에 쓰이는 터치스크린 패널을 제조한다. 일진디스플레이의 매출 90% 이상이 터치사업부에서 발생하고, 사파이어사업부의 매출 비중은 10%도 되지 않는다. 하지만 사파이어사업부에 대한 기대는 상당하다. 세계적으로 마이크로 LED 시장이 성장세에 있는데, 마이크로 LED 제조를 위해서는 사파이어 웨이퍼가 필요하기 때문이다. 마이크로 LED는 일반 LED에 비해 길이와 넓이가 각각 10분의 1, 100분의 1 수준이다. 다만, 아직까지는 기술력 등의 문제로 마이크로 LED를 사용하는 기기가 많지 않다. 시장조사기관 마켓앤드마켓은 마이크로 LED 시장 규모가 2020년 17억 달러(약 2조 1,250억 원)에서 2025년 199억 달러(약 25조 원)로 성장할 것으로 전망했다. 마이크로 LED는 스마트워치, 가상현실(VR) 등의 기기를 통해 시장이 형성되면서 향후에는 태블릿, 스마트폰 분야로 확대될 것으로 예상된다. 마이크로 LED 시장이 개화되면 사파이어 소재에 대한 수요가 급격히 늘어날 것으로 전망되며 사파이어 웨이퍼의 가격도 상승할 것으로 기대된다. 이 텍스트를 요약해줘.\n",
      "\n",
      "파인텍은 2008년 설립된 디스플레이 소재 선도 기업으로, 디스플레이 BLU 국산화와 폴더블 디스플레이 제조장비 개발에 기여했다. 최근에는 이차전지 장비와 센서 사업에서도 혁신을 추구하며 글로벌 일류 기업으로 성장하고 있다. 일진디스플레이는 사파이어와 터치스크린 패널을 생산하며, 마이크로 LED 시장의 성장으로 사파이어 웨이퍼에 대한 기대가 크다. 마이크로 LED 시장은 2025년까지 199억 달러로 성장할 것으로 예상되며, 사파이어 소재 수요도 증가할 것으로 기대된다.<eos>\n"
     ]
    }
   ],
   "source": [
    "# 예제 입력 텍스트\n",
    "input_text = \"파인텍은 2008년 설립해 끊임없는 R&D 투자와 우수 인력 확보로 전문적인 디스플레이 소재 분야의 선도 기업으로 성장해 왔다. 파인텍은 창립 이래 지속적인 연구 개발로 디스플레이 BLU를 국산화했고, 세계 최초로 폴더블 디스플레이 제조장비를 개발하는 등 디스플레이 산업에서 첨단 기술을 선도하는 기업으로 자리 잡았다. 파인텍은 디스플레이 토털 솔루션 기업을 뛰어넘어 이차전지 장비와 센서 사업에서의 끊임없는 도전과 혁신으로 글로벌 일류 기업으로 위상을 확고히 해 나가고 있다.일진디스플레이의 사업부는 크게 사파이어사업부와 터치사업부로 나뉜다. 사파이어사업부는 발광다이오드(LED)용 사파이어 웨이퍼를 주로 생산하고, 터치사업부는 휴대폰이나 태블릿에 쓰이는 터치스크린 패널을 제조한다. 일진디스플레이의 매출 90% 이상이 터치사업부에서 발생하고, 사파이어사업부의 매출 비중은 10%도 되지 않는다. 하지만 사파이어사업부에 대한 기대는 상당하다. 세계적으로 마이크로 LED 시장이 성장세에 있는데, 마이크로 LED 제조를 위해서는 사파이어 웨이퍼가 필요하기 때문이다. 마이크로 LED는 일반 LED에 비해 길이와 넓이가 각각 10분의 1, 100분의 1 수준이다. 다만, 아직까지는 기술력 등의 문제로 마이크로 LED를 사용하는 기기가 많지 않다. 시장조사기관 마켓앤드마켓은 마이크로 LED 시장 규모가 2020년 17억 달러(약 2조 1,250억 원)에서 2025년 199억 달러(약 25조 원)로 성장할 것으로 전망했다. 마이크로 LED는 스마트워치, 가상현실(VR) 등의 기기를 통해 시장이 형성되면서 향후에는 태블릿, 스마트폰 분야로 확대될 것으로 예상된다. 마이크로 LED 시장이 개화되면 사파이어 소재에 대한 수요가 급격히 늘어날 것으로 전망되며 사파이어 웨이퍼의 가격도 상승할 것으로 기대된다. 이 텍스트를 요약해줘.\"\n",
    "\n",
    "# plm 모델 사용\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "# 입력 텐서를 GPU로 이동\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "output = plm.generate(**inputs, max_length=1024)\n",
    "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Output:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    \"rouge1\": [],\n",
    "    \"rouge2\": [],\n",
    "    \"rougeL\": [],\n",
    "    \"rougeLsum\": []\n",
    "}\n",
    "\n",
    "target = \"파인텍은 2008년 설립 이후 디스플레이 소재 분야에서 R&D 투자와 인력 확보로 선도 기업으로 성장했으며, 디스플레이 BLU 국산화와 폴더블 디스플레이 제조장비 개발로 주목받고 있다. 또한, 이차전지 장비와 센서 사업에서도 글로벌 기업으로 자리매김하고 있다. 일진디스플레이는 사파이어사업부와 터치사업부로 나뉘며, 매출의 90% 이상이 터치사업부에서 발생한다. 사파이어사업부는 LED용 사파이어 웨이퍼를 생산하며, 마이크로 LED 시장의 성장으로 수요 증가가 기대된다. 마이크로 LED는 스마트워치와 VR 기기에서 시작해 태블릿과 스마트폰으로 확대될 전망이다.<eos>\"\n",
    "pred = \"파인텍은 2008년 설립된 디스플레이 소재 선도 기업으로, BLU 국산화와 폴더블 디스플레이 제조장비 개발로 첨단 기술을 선도하고 있다. 최근에는 이차전지 장비와 센서 사업에서도 혁신을 추구하며 글로벌 일류 기업으로 성장하고 있다. 일진디스플레이는 사파이어와 터치스크린 패널을 생산하며, 마이크로 LED 시장의 성장으로 사파이어 웨이퍼에 대한 기대감이 크다. 마이크로 LED 시장은 2025년까지 199억 달러로 성장할 것으로 전망되며, 사파이어 소재 수요도 증가할 것으로 기대된다.<eos>\"\n",
    "\n",
    "\n",
    "rscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'])\n",
    "rscore = rscorer.score(target, pred)\n",
    "for rouge_type in scores.keys():\n",
    "    scores[rouge_type].append(rscore[rouge_type].fmeasure)\n",
    "    \n",
    "avg_scores = {rouge_type: sum(score_list) / len(score_list) * 100 for rouge_type, score_list in scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 44.628099173553714, 'rouge2': 25.21008403361345, 'rougeL': 42.97520661157024, 'rougeLsum': 42.97520661157024}\n"
     ]
    }
   ],
   "source": [
    "print(avg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확장 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      "##Instruction : 전자랜드는 1988년 국내 최초로 최대 규모의 전자 유통 전문점의 새로운 활로를 개척했다. 전국 130여 개 매장 100%를 직영 중이며, 온라인 쇼핑몰을 운영하고 있다. 국내외 유수 업체의 생활 가전부터 음향/IT/모바일 가전을 넘어, 로봇/드론 등 미래 4차 산업 가전까지 다채로운 상품을 취급한다. 전국 무료 배송, 폐가전 무료 수거, 가전 청소 홈케어 서비스 등 다양한 고객 만족 서비스를 제공하고 있다. 이 텍스트를 확장해줘.\n",
      "\n",
      "##Response : \n",
      "\n",
      "전자랜드는 1988년에 설립된 국내 최초이자 최대 규모의 전자 유통 전문점으로, 당시 전자 제품 유통 시장에 새로운 활로를 개척한 선구적인 기업으로 평가받고 있습니다. 이 회사는 설립 이래로 꾸준히 성장하며, 현재 전국에 걸쳐 130여 개의 매장을 운영하고 있습니다. 모든 매장은 직영으로 운영되어, 고객들에게 일관된 서비스와 품질을 제공합니다. \n",
      "\n",
      "전자랜드는 단순히 제품을 판매하는 데 그치지 않고, 고객들에게 다양한 쇼핑 경험을 제공하기 위해 노력하고 있습니다. 이를 위해 온라인 쇼핑몰을 운영하며, 고객들이 언제 어디서나 편리하게 제품을 구매할 수 있도록 지원하고 있습니다. 온라인 쇼핑몰에서는 다양한 카테고리의 제품을 선보이고 있으며, 고객들이 원하는 제품을 쉽게 찾을 수 있도록 분류하고 있습니다.\n",
      "\n",
      "전자랜드는 단순한 가전제품 판매에 그치지 않고, 고객의 다양한 요구를 충족시키기 위해 노력하고 있습니다. 이를 위해 국내외 유수 업체의 생활 가전부터 음향/IT/모바일 가전을 취급하고 있으며, 최근에는 로봇과 드론 등 미래 4차 산업 가전까지 제품군을 확장하고 있습니다. 이러한 제품군 확장은 고객의 변화하는 요구를 충족시키고, 새로운 기술 트렌드를 선도하기 위한 전략의 일환입니다.\n",
      "\n",
      "전자랜드는 단순히 제품을 판매하는 데 그치지 않고, 고객 만족을 위한 다양한 서비스를 제공하고 있습니다. 예를 들어, 전국 무료 배송 서비스를 통해 고객들이 제품을 부담 없이 받을 수 있도록 지원하고 있으며, 폐가전 무료 수거 서비스를 통해 환경 보호에도 기여하고 있습니다. 또한, 가전 청소 홈케어 서비스를 통해 고객들이 제품을 보다 오래 사용할 수 있도록 지원하고 있습니다. 이러한 서비스들은 고객들에게 높은 만족도를 제공하며, 전자랜드의 브랜드 가치를 높이는 데 기여하고 있습니다.\n",
      "\n",
      "전자랜드는 앞으로도 지속적인 혁신과 고객 중심의 서비스를 통해 전자 제품 유통 시장에서 선도적인 위치를 유지하고자 합니다. 이를 위해 새로운 기술 도입과 고객 맞춤형 서비스 개발에 지속적으로 투자할 계획입니다. 이러한 노력은 고객들에게 보다 나은 쇼핑 경험을 제공하고, 전자랜드가 고객들에게 신뢰받는 브랜드로 자리매김하는 데 기여할 것입니다.<eos>\n"
     ]
    }
   ],
   "source": [
    "# 예제 입력 텍스트\n",
    "input_text = \"\"\"\n",
    "##Instruction : 전자랜드는 1988년 국내 최초로 최대 규모의 전자 유통 전문점의 새로운 활로를 개척했다. 전국 130여 개 매장 100%를 직영 중이며, 온라인 쇼핑몰을 운영하고 있다. 국내외 유수 업체의 생활 가전부터 음향/IT/모바일 가전을 넘어, 로봇/드론 등 미래 4차 산업 가전까지 다채로운 상품을 취급한다. 전국 무료 배송, 폐가전 무료 수거, 가전 청소 홈케어 서비스 등 다양한 고객 만족 서비스를 제공하고 있다. 이 텍스트를 확장해줘.\n",
    "\n",
    "##Response : \n",
    "\"\"\"\n",
    "\n",
    "# FLM 모델 사용\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# 입력 텐서를 GPU로 이동\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "# 모델 실행\n",
    "output = flm.generate(**inputs, max_length=1024)\n",
    "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Output:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    \"rouge1\": [],\n",
    "    \"rouge2\": [],\n",
    "    \"rougeL\": [],\n",
    "    \"rougeLsum\": []\n",
    "}\n",
    "\n",
    "target = \"\"\"전자랜드는 1988년에 설립되어 국내 최초로 최대 규모의 전자 유통 전문점이라는 새로운 시장을 개척한 기업입니다. 이 회사는 전자 제품 유통 분야에서 선구적인 역할을 하며, 현재 전국에 걸쳐 130여 개의 매장을 운영하고 있습니다. 모든 매장은 100% 직영으로 관리되어, 일관된 서비스와 품질을 고객에게 제공하고 있습니다. \n",
    "\n",
    "전자랜드는 오프라인 매장뿐만 아니라 온라인 쇼핑몰도 운영하고 있어, 고객들이 언제 어디서나 편리하게 쇼핑할 수 있는 환경을 제공합니다. 이 온라인 플랫폼은 다양한 전자 제품을 손쉽게 비교하고 구매할 수 있는 기능을 갖추고 있어, 바쁜 현대인들에게 큰 편의를 제공합니다.\n",
    "\n",
    "취급하는 제품군은 매우 다양합니다. 전통적인 생활 가전 제품에서부터 최신 음향 기기, IT 기기, 모바일 가전 제품에 이르기까지 폭넓은 선택지를 제공합니다. 또한, 로봇과 드론 같은 첨단 기술을 활용한 미래 4차 산업 관련 가전 제품도 취급하고 있어, 기술 발전에 민감한 소비자들의 요구를 충족시키고 있습니다.\n",
    "\n",
    "전자랜드는 고객 만족을 최우선으로 생각하며, 다양한 부가 서비스를 통해 고객의 편의를 도모하고 있습니다. 전국 어디서나 무료로 배송 서비스를 제공하여, 고객이 원하는 장소에서 제품을 손쉽게 받을 수 있도록 하고 있습니다. 또한, 사용하지 않는 폐가전을 무료로 수거해주는 서비스를 제공하여, 환경 보호에도 기여하고 있습니다. 더불어, 가전 제품의 청소와 유지 관리를 돕는 홈케어 서비스도 제공하여, 고객이 구매한 제품을 오랫동안 최상의 상태로 사용할 수 있도록 지원하고 있습니다.\n",
    "\n",
    "이러한 다양한 서비스와 제품군을 통해 전자랜드는 고객에게 신뢰받는 브랜드로 자리매김하고 있으며, 끊임없이 변화하는 시장 환경 속에서도 지속적인 성장을 이루고 있습니다. 앞으로도 전자랜드는 혁신적인 제품과 서비스를 통해 고객의 삶을 더욱 풍요롭게 만들기 위해 노력할 것입니다.<eos>\"\"\"\n",
    "pred = \"\"\"\n",
    "전자랜드는 1988년에 설립된 국내 최초이자 최대 규모의 전자 유통 전문점으로, 당시 전자 제품 유통 시장에 새로운 활로를 개척한 선구적인 기업으로 평가받고 있습니다. 이 회사는 설립 이래로 꾸준히 성장하며, 현재 전국에 걸쳐 130여 개의 매장을 운영하고 있습니다. 모든 매장은 직영으로 운영되어, 고객들에게 일관된 서비스와 품질을 제공합니다. \n",
    "\n",
    "전자랜드는 단순히 제품을 판매하는 데 그치지 않고, 고객들에게 다양한 쇼핑 경험을 제공하기 위해 노력하고 있습니다. 이를 위해 온라인 쇼핑몰을 운영하며, 고객들이 언제 어디서나 편리하게 제품을 구매할 수 있도록 지원하고 있습니다. 온라인 쇼핑몰에서는 다양한 카테고리의 제품을 선보이고 있으며, 고객들이 원하는 제품을 쉽게 찾을 수 있도록 분류하고 있습니다.\n",
    "\n",
    "전자랜드는 단순한 가전제품 판매에 그치지 않고, 고객의 다양한 요구를 충족시키기 위해 노력하고 있습니다. 이를 위해 국내외 유수 업체의 생활 가전부터 음향/IT/모바일 가전을 취급하고 있으며, 최근에는 로봇과 드론 등 미래 4차 산업 가전까지 제품군을 확장하고 있습니다. 이러한 제품군 확장은 고객의 변화하는 요구를 충족시키고, 새로운 기술 트렌드를 선도하기 위한 전략의 일환입니다.\n",
    "\n",
    "전자랜드는 단순히 제품을 판매하는 데 그치지 않고, 고객 만족을 위한 다양한 서비스를 제공하고 있습니다. 예를 들어, 전국 무료 배송 서비스를 통해 고객들이 제품을 부담 없이 받을 수 있도록 지원하고 있으며, 폐가전 무료 수거 서비스를 통해 환경 보호에도 기여하고 있습니다. 또한, 가전 청소 홈케어 서비스를 통해 고객들이 제품을 보다 오래 사용할 수 있도록 지원하고 있습니다. 이러한 서비스들은 고객들에게 높은 만족도를 제공하며, 전자랜드의 브랜드 가치를 높이는 데 기여하고 있습니다.\n",
    "\n",
    "전자랜드는 앞으로도 지속적인 혁신과 고객 중심의 서비스를 통해 전자 제품 유통 시장에서 선도적인 위치를 유지하고자 합니다. 이를 위해 새로운 기술 도입과 고객 맞춤형 서비스 개발에 지속적으로 투자할 계획입니다. 이러한 노력은 고객들에게 보다 나은 쇼핑 경험을 제공하고, 전자랜드가 고객들에게 신뢰받는 브랜드로 자리매김하는 데 기여할 것입니다.<eos>\"\"\"\n",
    "\n",
    "\n",
    "rscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'])\n",
    "rscore = rscorer.score(target, pred)\n",
    "for rouge_type in scores.keys():\n",
    "    scores[rouge_type].append(rscore[rouge_type].fmeasure)\n",
    "    \n",
    "avg_scores = {rouge_type: sum(score_list) / len(score_list) * 100 for rouge_type, score_list in scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 44.44444444444444, 'rouge2': 18.884120171673818, 'rougeL': 32.47863247863248, 'rougeLsum': 37.95309168443497}\n"
     ]
    }
   ],
   "source": [
    "print(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 전자랜드는 1988년 국내 최초로 최대 규모의 전자 유통 전문점의 새로운 활로를 개척했다. 전국 130여 개 매장 100%를 직영 중이며, 온라인 쇼핑몰을 운영하고 있다. 국내외 유수 업체의 생활 가전부터 음향/IT/모바일 가전을 넘어, 로봇/드론 등 미래 4차 산업 가전까지 다채로운 상품을 취급한다. 전국 무료 배송, 폐가전 무료 수거, 가전 청소 홈케어 서비스 등 다양한 고객 만족 서비스를 제공하고 있다. 이 텍스트를 확장해줘.\n",
      "\n",
      "전자랜드는 1988년에 설립된 전자 제품 유통 전문점으로, 당시 국내에서는 최초로 대규모 전자 제품 전문점을 운영하며 새로운 유통 채널을 개척한 선구적인 기업으로 평가받고 있습니다. 이 회사는 설립 이래로 꾸준히 성장하여 현재 전국에 걸쳐 130여 개의 매장을 운영하고 있으며, 모든 매장을 직접 운영하는 직영 체제를 유지하고 있습니다. 이러한 직영 체제는 고객들에게 보다 일관되고 신뢰할 수 있는 서비스를 제공하는 데 기여하고 있습니다.\n",
      "\n",
      "전자랜드는 단순한 전자 제품 판매에 그치지 않고, 온라인 쇼핑몰을 운영하며 온라인 시장에서도 강력한 입지를 다지고 있습니다. 온라인 쇼핑몰을 통해 고객들은 다양한 제품을 쉽게 검색하고 구매할 수 있으며, 이는 고객 편의성을 크게 향상시켰습니다. 또한, 전자랜드는 국내외 유수 업체의 생활 가전 제품을 비롯하여 음향, IT, 모바일 가전을 포함한 다양한 카테고리의 제품을 취급하고 있습니다. 이는 고객들이 다양한 제품을 한 곳에서 비교하고 구매할 수 있는 기회를 제공합니다.\n",
      "\n",
      "전자랜드는 단순히 제품을 판매하는 데 그치지 않고, 고객 만족을 위한 다양한 서비스를 제공하고 있습니다. 예를 들어, 전국 무료 배송 서비스를 통해 고객들이 제품을 편리하게 받을 수 있도록 지원하며, 폐가전 무료 수거 서비스를 통해 환경 보호에도 기여하고 있습니다. 또한, 가전 청소 홈케어 서비스를 통해 고객들이 가전제품을 보다 청결하게 사용할 수 있도록 돕고 있습니다. 이러한 서비스들은 고객들에게 높은 만족도를 제공하며, 전자랜드의 브랜드 가치를 높이는 데 기여하고 있습니다.\n",
      "\n",
      "최근에는 로봇과 드론 등 미래 4차 산업 가전 제품까지 취급 범위를 확장하고 있습니다. 이는 전자랜드가 미래 기술 트렌드를 선도하고, 고객들에게 혁신적인 제품을 제공하려는 의지를 보여줍니다. 이러한 노력은 전자랜드가 앞으로도 지속적으로 성장할 수 있는 기반을 마련하는 데 중요한 역할을 하고 있습니다. 전자랜드는 앞으로도 고객 만족을 최우선으로 생각하며, 다양한 제품과 서비스를 통해 고객들에게 최상의 경험을 제공하고자 노력하고 있습니다.<eos>\n"
     ]
    }
   ],
   "source": [
    "# 예제 입력 텍스트\n",
    "input_text = \"전자랜드는 1988년 국내 최초로 최대 규모의 전자 유통 전문점의 새로운 활로를 개척했다. 전국 130여 개 매장 100%를 직영 중이며, 온라인 쇼핑몰을 운영하고 있다. 국내외 유수 업체의 생활 가전부터 음향/IT/모바일 가전을 넘어, 로봇/드론 등 미래 4차 산업 가전까지 다채로운 상품을 취급한다. 전국 무료 배송, 폐가전 무료 수거, 가전 청소 홈케어 서비스 등 다양한 고객 만족 서비스를 제공하고 있다. 이 텍스트를 확장해줘.\"\n",
    "\n",
    "# plm 모델 사용\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "# 입력 텐서를 GPU로 이동\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "output = plm.generate(**inputs, max_length=1024)\n",
    "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Output:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    \"rouge1\": [],\n",
    "    \"rouge2\": [],\n",
    "    \"rougeL\": [],\n",
    "    \"rougeLsum\": []\n",
    "}\n",
    "\n",
    "target = \"\"\"전자랜드는 1988년에 설립되어 국내 최초로 최대 규모의 전자 유통 전문점이라는 새로운 시장을 개척한 기업입니다. 이 회사는 전자 제품 유통 분야에서 선구적인 역할을 하며, 현재 전국에 걸쳐 130여 개의 매장을 운영하고 있습니다. 모든 매장은 100% 직영으로 관리되어, 일관된 서비스와 품질을 고객에게 제공하고 있습니다. \n",
    "\n",
    "전자랜드는 오프라인 매장뿐만 아니라 온라인 쇼핑몰도 운영하고 있어, 고객들이 언제 어디서나 편리하게 쇼핑할 수 있는 환경을 제공합니다. 이 온라인 플랫폼은 다양한 전자 제품을 손쉽게 비교하고 구매할 수 있는 기능을 갖추고 있어, 바쁜 현대인들에게 큰 편의를 제공합니다.\n",
    "\n",
    "취급하는 제품군은 매우 다양합니다. 전통적인 생활 가전 제품에서부터 최신 음향 기기, IT 기기, 모바일 가전 제품에 이르기까지 폭넓은 선택지를 제공합니다. 또한, 로봇과 드론 같은 첨단 기술을 활용한 미래 4차 산업 관련 가전 제품도 취급하고 있어, 기술 발전에 민감한 소비자들의 요구를 충족시키고 있습니다.\n",
    "\n",
    "전자랜드는 고객 만족을 최우선으로 생각하며, 다양한 부가 서비스를 통해 고객의 편의를 도모하고 있습니다. 전국 어디서나 무료로 배송 서비스를 제공하여, 고객이 원하는 장소에서 제품을 손쉽게 받을 수 있도록 하고 있습니다. 또한, 사용하지 않는 폐가전을 무료로 수거해주는 서비스를 제공하여, 환경 보호에도 기여하고 있습니다. 더불어, 가전 제품의 청소와 유지 관리를 돕는 홈케어 서비스도 제공하여, 고객이 구매한 제품을 오랫동안 최상의 상태로 사용할 수 있도록 지원하고 있습니다.\n",
    "\n",
    "이러한 다양한 서비스와 제품군을 통해 전자랜드는 고객에게 신뢰받는 브랜드로 자리매김하고 있으며, 끊임없이 변화하는 시장 환경 속에서도 지속적인 성장을 이루고 있습니다. 앞으로도 전자랜드는 혁신적인 제품과 서비스를 통해 고객의 삶을 더욱 풍요롭게 만들기 위해 노력할 것입니다.<eos>\"\"\"\n",
    "pred = \"\"\"\n",
    "전자랜드는 1988년에 설립된 전자 제품 유통 전문점으로, 당시 국내에서는 최초로 대규모 전자 제품 전문점을 운영하며 새로운 유통 채널을 개척한 선구적인 기업으로 평가받고 있습니다. 이 회사는 설립 이래로 꾸준히 성장하여 현재 전국에 걸쳐 130여 개의 매장을 운영하고 있으며, 모든 매장을 직접 운영하는 직영 체제를 유지하고 있습니다. 이러한 직영 체제는 고객들에게 보다 일관되고 신뢰할 수 있는 서비스를 제공하는 데 기여하고 있습니다.\n",
    "\n",
    "전자랜드는 단순한 전자 제품 판매에 그치지 않고, 온라인 쇼핑몰을 운영하며 온라인 시장에서도 강력한 입지를 다지고 있습니다. 온라인 쇼핑몰을 통해 고객들은 다양한 제품을 쉽게 검색하고 구매할 수 있으며, 이는 고객 편의성을 크게 향상시켰습니다. 또한, 전자랜드는 국내외 유수 업체의 생활 가전 제품을 비롯하여 음향, IT, 모바일 가전을 포함한 다양한 카테고리의 제품을 취급하고 있습니다. 이는 고객들이 다양한 제품을 한 곳에서 비교하고 구매할 수 있는 기회를 제공합니다.\n",
    "\n",
    "전자랜드는 단순히 제품을 판매하는 데 그치지 않고, 고객 만족을 위한 다양한 서비스를 제공하고 있습니다. 예를 들어, 전국 무료 배송 서비스를 통해 고객들이 제품을 편리하게 받을 수 있도록 지원하며, 폐가전 무료 수거 서비스를 통해 환경 보호에도 기여하고 있습니다. 또한, 가전 청소 홈케어 서비스를 통해 고객들이 가전제품을 보다 청결하게 사용할 수 있도록 돕고 있습니다. 이러한 서비스들은 고객들에게 높은 만족도를 제공하며, 전자랜드의 브랜드 가치를 높이는 데 기여하고 있습니다.\n",
    "\n",
    "최근에는 로봇과 드론 등 미래 4차 산업 가전 제품까지 취급 범위를 확장하고 있습니다. 이는 전자랜드가 미래 기술 트렌드를 선도하고, 고객들에게 혁신적인 제품을 제공하려는 의지를 보여줍니다. 이러한 노력은 전자랜드가 앞으로도 지속적으로 성장할 수 있는 기반을 마련하는 데 중요한 역할을 하고 있습니다. 전자랜드는 앞으로도 고객 만족을 최우선으로 생각하며, 다양한 제품과 서비스를 통해 고객들에게 최상의 경험을 제공하고자 노력하고 있습니다.<eos>\"\"\"\n",
    "\n",
    "\n",
    "rscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'])\n",
    "rscore = rscorer.score(target, pred)\n",
    "for rouge_type in scores.keys():\n",
    "    scores[rouge_type].append(rscore[rouge_type].fmeasure)\n",
    "    \n",
    "avg_scores = {rouge_type: sum(score_list) / len(score_list) * 100 for rouge_type, score_list in scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 42.17391304347826, 'rouge2': 17.03056768558952, 'rougeL': 26.086956521739136, 'rougeLsum': 37.391304347826086}\n"
     ]
    }
   ],
   "source": [
    "print(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f45b9debb84f27aa8e91e163c8b69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/277M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/MartinusChoi/FinPilot-EEVE-Korean-10.8B-1.0.0/commit/a4a89fb991673fff6ef3b32c371ae94473e92615', commit_message='Upload model', commit_description='', oid='a4a89fb991673fff6ef3b32c371ae94473e92615', pr_url=None, repo_url=RepoUrl('https://huggingface.co/MartinusChoi/FinPilot-EEVE-Korean-10.8B-1.0.0', endpoint='https://huggingface.co', repo_type='model', repo_id='MartinusChoi/FinPilot-EEVE-Korean-10.8B-1.0.0'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flm.push_to_hub(\"MartinusChoi/FinPilot-EEVE-Korean-10.8B-1.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = flm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # llama.cpp 클론\n",
    "# !git clone https://github.com/ggerganov/llama.cpp.git\n",
    "# !cd llama.cpp && make\n",
    "\n",
    "# # Python 의존성 설치\n",
    "# !pip install -r requirements.txt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
