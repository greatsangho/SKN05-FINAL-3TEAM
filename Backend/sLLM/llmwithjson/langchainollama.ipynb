{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.34 (from langchain)\n",
      "  Downloading langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.38-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.12-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain)\n",
      "  Downloading numpy-2.2.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.34->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\greatsangho\\documents\\git\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<1.0.0,>=0.3.34->langchain)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain-0.3.18-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 2.1/2.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading aiohttp-3.11.12-cp312-cp312-win_amd64.whl (437 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading langchain_core-0.3.34-py3-none-any.whl (412 kB)\n",
      "Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Downloading langsmith-0.3.8-py3-none-any.whl (332 kB)\n",
      "Downloading numpy-2.2.2-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.4/12.6 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.7/12.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.6 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 11.1 MB/s eta 0:00:00\n",
      "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Downloading SQLAlchemy-2.0.38-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 13.0 MB/s eta 0:00:00\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-extensions, tenacity, sniffio, PyYAML, python-dotenv, propcache, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpointer, idna, httpx-sse, h11, greenlet, frozenlist, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests, pydantic-core, jsonpatch, httpcore, anyio, aiosignal, requests-toolbelt, pydantic, httpx, dataclasses-json, aiohttp, pydantic-settings, langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.38 aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.8.0 attrs-25.1.0 certifi-2025.1.31 charset-normalizer-3.4.1 dataclasses-json-0.6.7 frozenlist-1.5.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 httpx-sse-0.4.0 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.18 langchain-core-0.3.34 langchain-text-splitters-0.3.6 langchain_community-0.3.17 langsmith-0.3.8 marshmallow-3.26.1 multidict-6.1.0 mypy-extensions-1.0.0 numpy-2.2.2 orjson-3.10.15 propcache-0.2.1 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.7.1 python-dotenv-1.0.1 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 typing-extensions-4.12.2 typing-inspect-0.9.0 urllib3-2.3.0 yarl-1.18.3 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_community requests langserve fastapi -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 404, {\"detail\":\"Not Found\"}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "import requests\n",
    "\n",
    "# LangServe API URL (ngrok URL + /ollama/invoke)\n",
    "langserve_url = \"https://termite-upward-monthly.ngrok-free.app/ollama/invoke\"\n",
    "\n",
    "# Generate a random config_hash\n",
    "def generate_random_hash(length=8):\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "# Function to send LLM request\n",
    "def llm_request(input_payload, config_hash):\n",
    "    # Headers for the request\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Make a POST request to the LangServe endpoint\n",
    "    response = requests.post(\n",
    "        f\"{langserve_url}?config_hash={config_hash}\",\n",
    "        json=input_payload,\n",
    "        headers=headers\n",
    "    )\n",
    "\n",
    "    # Check if the request was successful and return the response\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return {\"error\": f\"Error: {response.status_code}, {response.text}\"}\n",
    "\n",
    "# Function to create input payload with SystemMessage and HumanMessage\n",
    "def create_input_payload(system_message_content, human_message_content):\n",
    "    payload = {\n",
    "        \"input\": [\n",
    "            {\n",
    "                \"type\": \"system\",\n",
    "                \"content\": system_message_content\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"human\",\n",
    "                \"content\": human_message_content\n",
    "            }\n",
    "        ],\n",
    "        \"config\": {\n",
    "            \"max_tokens\": 100,\n",
    "            \"temperature\": 0.7,\n",
    "            \"stream\": False,  # Include additional parameters if needed\n",
    "            \"log_level\": \"debug\"  # Include additional parameters if needed\n",
    "        }\n",
    "    }\n",
    "    return payload\n",
    "\n",
    "# Main function to get the answer from the LLM\n",
    "def get_answer(system_message, human_message):\n",
    "    config_hash = generate_random_hash()\n",
    "    input_payload = create_input_payload(system_message, human_message)\n",
    "    response = llm_request(input_payload, config_hash)\n",
    "\n",
    "    # Extract the answer from the response JSON\n",
    "    if \"output\" in response and \"content\" in response[\"output\"]:\n",
    "        return response[\"output\"][\"content\"]\n",
    "    elif \"error\" in response:\n",
    "        return response[\"error\"]\n",
    "    else:\n",
    "        return \"No valid response received.\"\n",
    "\n",
    "# Define SystemMessage and HumanMessage content\n",
    "system_message = (\n",
    "    \"A chat between a curious user and an artificial intelligence assistant. \"\n",
    "    \"The assistant gives helpful, detailed, and polite answers to the user's questions.\"\n",
    ")\n",
    "# human_message = (\n",
    "#     \"한국의 수도는 어디인가요? 아래 선택지 중 골라주세요.\\n\\n\"\n",
    "#     \"(A) 경성\\n(B) 부산\\n(C) 평양\\n(D) 서울\\n(E) 전주\"\n",
    "# )\n",
    "human_message = \"최근 코스피 동향 알려줘\"\n",
    "\n",
    "# Get the answer from the LLM\n",
    "answer = get_answer(system_message, human_message)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 궁금한 점을 도와드리기 위해 여기에 있습니다. 저는 도움이 되고 존중하는 조수로서 정확하고 유용한 정보를 제공하기 위해 최선을 다할 것입니다. 질문이 있거나 더 알고 싶은 주제가 있다면 언제든지 물어보세요. 안전하고 사회적 편견이 없으며 사실적으로 일관된 답변을 드리기 위해 노력하겠습니다.\n",
      "\n",
      "질문에 대한 답변이나 주제에 대해 자세히 설명해 드릴 때, 항상 사실에 기반한 정보만을 제공하며 검증되지 않았거나 해로운 내용은 피하도록 하겠습니다. 또한 여러분의 질문이 말이 되지 않거나 사실과 맞지 않는 경우, 잘못된 정보를 제공하는 대신 왜 그런지 설명드리겠습니다.\n",
      "\n",
      "더 많은 맥락이나 배경 지식이 필요하다고 생각되면 언제든지 요청하겠습니다. 그리고 제가 모르는 주제에 대해서는 모른다고 솔직히 말씀드리고 더 조사하거나 관련 분야의 전문가에게 도움을 구하는 방법을 제안하겠습니다.\n",
      "\n",
      "질문을 하거나 주제를 논의하고 싶으시다면 주저하지 마시고 편하게 물어보세요! 최선을 다해 도와드리겠습니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# LangServe API URL (ngrok URL + /prompt/invoke)\n",
    "langserve_url = \"https://termite-upward-monthly.ngrok-free.app/prompt/invoke\"\n",
    "\n",
    "# Generate a random config_hash\n",
    "def generate_random_hash(length=8):\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "\n",
    "# Function to send LLM request matching the cURL payload\n",
    "def llm_request(topic):\n",
    "    # Use static config_hash as in the cURL command\n",
    "    config_hash = generate_random_hash()\n",
    "    \n",
    "    # Create payload exactly as shown in the cURL example\n",
    "    payload = {\n",
    "        \"input\": {\n",
    "            \"topic\": topic\n",
    "        },\n",
    "        \"config\": {},\n",
    "        \"kwargs\": {}\n",
    "    }\n",
    "    \n",
    "    # Define request headers\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Make the POST request to the endpoint with the config_hash in the query string\n",
    "    response = requests.post(f\"{langserve_url}?config_hash={config_hash}\", json=payload, headers=headers)\n",
    "    \n",
    "    # Return the JSON response if successful, otherwise return the error details\n",
    "    if response.status_code == 200:\n",
    "        answer = response.json().get(\"output\", {})\n",
    "        return answer\n",
    "    else:\n",
    "        return {\"error\": f\"Error: {response.status_code}, {response.text}\"}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the topic exactly as needed (for example: \"hello\")\n",
    "    topic = \"hello\"\n",
    "    \n",
    "    # Send the request and print the answer\n",
    "    answer = llm_request(topic)\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
